{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T07:09:03.741480Z",
     "start_time": "2024-10-28T07:09:03.737273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import HandTrackingModule as htm"
   ],
   "id": "79fa2ac072d9619b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T07:09:03.769878Z",
     "start_time": "2024-10-28T07:09:03.765808Z"
    }
   },
   "cell_type": "code",
   "source": "wCam, hCam = 1280, 720",
   "id": "c8250e19baf16d8d",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T07:09:04.268769Z",
     "start_time": "2024-10-28T07:09:03.779415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, wCam)\n",
    "cap.set(4, hCam)\n",
    "pTime = 0"
   ],
   "id": "e5776f9dbebed2cb",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T07:09:04.298387Z",
     "start_time": "2024-10-28T07:09:04.280335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "detector = htm.handDetector()\n",
    "\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(\n",
    "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = interface.QueryInterface(IAudioEndpointVolume)\n",
    "# volume.GetMute()\n",
    "# volume.GetMasterVolumeLevel()\n",
    "volRange = volume.GetVolumeRange()\n",
    "volume.SetMasterVolumeLevel(0, None)\n",
    "minVol = volRange[0]\n",
    "maxVol = volRange[1]\n",
    "vol = 0\n",
    "volBar = 400\n",
    "volPer = 0"
   ],
   "id": "faf5f591631fd708",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T07:10:11.380016Z",
     "start_time": "2024-10-28T07:09:04.311514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    # Capture frame from video feed\n",
    "    success, img = cap.read()\n",
    "    img = detector.findHands(img)\n",
    "    lmList = detector.findPosition(img, draw=False)\n",
    "    \n",
    "    if len(lmList) != 0:\n",
    "        # Retrieve coordinates of index and thumb\n",
    "        x1, y1 = lmList[4][1], lmList[4][2]  # Thumb tip\n",
    "        x2, y2 = lmList[8][1], lmList[8][2]  # Index tip\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # Center point\n",
    "\n",
    "        # Draw circles with gradient colors\n",
    "        cv2.circle(img, (x1, y1), 12, (240, 128, 128), -1)\n",
    "        cv2.circle(img, (x2, y2), 12, (135, 206, 250), -1)\n",
    "        cv2.circle(img, (cx, cy), 10, (255, 255, 255), -1)\n",
    "\n",
    "        # Draw a smooth line with thicker width\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (50, 205, 50), 4)\n",
    "        \n",
    "        # Calculate length between thumb and index finger\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        # Map hand distance to volume range\n",
    "        vol = np.interp(length, [50, 300], [minVol, maxVol])\n",
    "        volPer = np.interp(length, [50, 300], [0, 100])\n",
    "        volBar = np.interp(length, [50, 300], [400, 150])\n",
    "\n",
    "        # Set volume based on distance\n",
    "        volume.SetMasterVolumeLevel(vol, None)\n",
    "\n",
    "        # Change color when distance is small\n",
    "        if length < 50:\n",
    "            cv2.circle(img, (cx, cy), 15, (0, 0, 0), -1)\n",
    "\n",
    "    # Draw a sleek, gradient-filled volume bar\n",
    "    overlay = img.copy()\n",
    "    cv2.rectangle(overlay, (50, 150), (85, 400), (255, 255, 255), 3)\n",
    "    cv2.rectangle(overlay, (50, int(volBar)), (85, 400), (0, 255, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.6, img, 0.4, 0, img)\n",
    "\n",
    "    # Display volume percentage with a transparent background for the text\n",
    "    cv2.rectangle(img, (40, 680), (200, 720), (0, 0, 0, 150), -1)\n",
    "    cv2.putText(img, f'Volume: {int(volPer)}%', (45, 710), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate and display FPS with a transparent background\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    cv2.rectangle(img, (30, 30), (150, 70), (0, 0, 0, 150), -1)\n",
    "    cv2.putText(img, f'FPS: {int(fps)}', (40, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Show image frame\n",
    "    cv2.imshow('Enhanced Hand Tracking Volume Control', img)\n",
    "    cv2.waitKey(1)"
   ],
   "id": "9749a1b529ea64af",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# Capture frame from video feed\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     success, img \u001B[38;5;241m=\u001B[39m cap\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m----> 4\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mdetector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfindHands\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     lmList \u001B[38;5;241m=\u001B[39m detector\u001B[38;5;241m.\u001B[39mfindPosition(img, draw\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(lmList) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;66;03m# Retrieve coordinates of index and thumb\u001B[39;00m\n",
      "File \u001B[1;32mW:\\coding\\simple-object-detection\\HandTrackingModule.py:24\u001B[0m, in \u001B[0;36mhandDetector.findHands\u001B[1;34m(self, img, draw)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfindHands\u001B[39m(\u001B[38;5;28mself\u001B[39m, img, draw\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     23\u001B[0m     imgRGB \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(img, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhands\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgRGB\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;66;03m# print(results.multi_hand_landmarks)\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults\u001B[38;5;241m.\u001B[39mmulti_hand_landmarks:\n",
      "File \u001B[1;32mW:\\coding\\python\\testing\\.venv\\Lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001B[0m, in \u001B[0;36mHands.process\u001B[1;34m(self, image)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, image: np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NamedTuple:\n\u001B[0;32m    133\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001B[39;00m\n\u001B[0;32m    134\u001B[0m \n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;124;03m         right hand) of the detected hand.\u001B[39;00m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mW:\\coding\\python\\testing\\.venv\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001B[0m, in \u001B[0;36mSolutionBase.process\u001B[1;34m(self, input_data)\u001B[0m\n\u001B[0;32m    334\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    335\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph\u001B[38;5;241m.\u001B[39madd_packet_to_input_stream(\n\u001B[0;32m    336\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream_name,\n\u001B[0;32m    337\u001B[0m         packet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_packet(input_stream_type,\n\u001B[0;32m    338\u001B[0m                                  data)\u001B[38;5;241m.\u001B[39mat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_simulated_timestamp))\n\u001B[1;32m--> 340\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait_until_idle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001B[39;00m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;66;03m# output stream names.\u001B[39;00m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_stream_type_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fdd2b52ac875d81c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
